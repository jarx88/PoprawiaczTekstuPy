# from .base_client import APIConnectionError, APIResponseError, DEFAULT_TIMEOUT # Zakomentowano - nieu≈ºywane w tym pliku
import time # Dla symulacji op√≥≈∫nienia
import openai
import os
import sys # Dodano import sys
from datetime import datetime
import ssl
import httpx
from httpx import HTTPError, TimeoutException
# PyQt6 removed - using CustomTkinter GUI now
from gui.prompts import get_system_prompt
from .base_client import DEFAULT_TIMEOUT, QUICK_TIMEOUT, CONNECTION_TIMEOUT, DEFAULT_RETRIES, APITimeoutError

# Importujemy logger z odpowiedniego miejsca w strukturze projektu
# Zak≈Çadamy, ≈ºe api_clients jest na tym samym poziomie co utils
# wiƒôc potrzebujemy .utils.logger
try:
    from utils.logger import logger
    from utils.config_manager import get_config_value
except ImportError:
    # Fallback logger w przypadku problem√≥w z importem (np. bezpo≈õrednie uruchamianie)
    import logging
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO) # Domy≈õlny poziom dla fallbacka
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# Klucz API OpenAI jest teraz przekazywany jako argument do funkcji,
# ale mo≈ºna te≈º ustawiƒá go globalnie przez zmiennƒÖ ≈õrodowiskowƒÖ OPENAI_API_KEY
# Je≈õli chcesz u≈ºywaƒá zmiennej ≈õrodowiskowej, odkomentuj:
# openai.api_key = os.getenv("OPENAI_API_KEY")

# Tymczasowo usuwamy import relatywny, je≈õli bƒôdziemy go potrzebowaƒá p√≥≈∫niej, przywr√≥cimy
# from .base_client import APIConnectionError, APIResponseError, DEFAULT_TIMEOUT

def show_connection_error():
    """Log connection error - GUI now handled by main application"""
    logger.error("Connection error - cannot connect to API server")
    logger.error("Possible causes: 1) No internet 2) Firewall blocking 3) API server down")

def handle_api_error(e):
    if isinstance(e, (httpx.ConnectError, httpx.ConnectTimeout, openai.APIConnectionError)):
        logger.error(f"B≈ÇƒÖd po≈ÇƒÖczenia: {str(e)}")
        show_connection_error()
        return True
    return False

def correct_text_openai(api_key, model, text_to_correct, instruction_prompt, system_prompt):
    """Poprawia tekst u≈ºywajƒÖc OpenAI API."""
    
        
    if not api_key:
        logger.warning("Pr√≥ba u≈ºycia OpenAI API bez klucza.") # Logowanie ostrze≈ºenia
        return "B≈ÇƒÖd: Klucz API OpenAI nie zosta≈Ç podany."
    if not model:
        logger.warning("Pr√≥ba u≈ºycia OpenAI API bez podania modelu.") # Logowanie ostrze≈ºenia
        return "B≈ÇƒÖd: Model OpenAI nie zosta≈Ç okre≈õlony."
    if not text_to_correct:
        logger.warning("Pr√≥ba u≈ºycia OpenAI API bez tekstu do poprawy.") # Logowanie ostrze≈ºenia
        return "B≈ÇƒÖd: Brak tekstu do poprawy."

    logger.info(f"Wysy≈Çanie zapytania do OpenAI API (model: {model}). Tekst: {text_to_correct[:50]}...") # Logowanie rozpoczƒôcia zapytania

    try:
        # Inicjalizacja klienta OpenAI z ulepszonƒÖ konfiguracjƒÖ
        client = openai.OpenAI(
            api_key=api_key,
            timeout=httpx.Timeout(
                connect=CONNECTION_TIMEOUT,  # 5s na po≈ÇƒÖczenie
                read=DEFAULT_TIMEOUT,        # 15s na odczyt
                write=CONNECTION_TIMEOUT,    # 5s na zapis
                pool=CONNECTION_TIMEOUT      # 5s na pool
            ),
            max_retries=DEFAULT_RETRIES,  # 2 pr√≥by zamiast 3
            http_client=httpx.Client(
                timeout=httpx.Timeout(
                    connect=CONNECTION_TIMEOUT,
                    read=DEFAULT_TIMEOUT,
                    write=CONNECTION_TIMEOUT,
                    pool=CONNECTION_TIMEOUT
                )
            )
        )

        # Pobierz odpowiedni system prompt w zale≈ºno≈õci od stylu
        current_system_prompt = get_system_prompt("prompt" if "prompt" in instruction_prompt.lower() else "normal")
        
        # Przygotowanie wiadomo≈õci dla Chat Completions API
        messages = [
            {"role": "system", "content": current_system_prompt},
            {"role": "user", "content": f"{instruction_prompt}\n\n---\n{text_to_correct}\n---"}
        ]

        # Wys≈Çanie zapytania do API z timeout
        response = None
        
        logger.info(f"üîç DEBUG: Rozpoczynam korekcjƒô dla modelu: {model}")

        # U≈ºyj Responses API dla wszystkich nowych modeli (w tym gpt-5-nano)
        use_responses_api = any(model.lower().startswith(prefix) for prefix in ["gpt-5", "o4", "o3", "o1"])
        
        logger.info(f"üîç DEBUG: Model: {model}, use_responses_api: {use_responses_api}")
        
        try:
            if use_responses_api:
                # Responses API dla nowszych modeli z reasoning controls
                # Pobierz ustawienia z config.ini lub u≈ºyj domy≈õlnych
                try:
                    import configparser
                    from utils.config_manager import get_config_path
                    config = configparser.ConfigParser()
                    config.read(get_config_path())
                    reasoning_effort = get_config_value(config, "AI_SETTINGS", "ReasoningEffort", "high")
                    verbosity = get_config_value(config, "AI_SETTINGS", "Verbosity", "medium")
                except:
                    # Fallback values je≈õli problem z konfiguracjƒÖ
                    reasoning_effort = "high"
                    verbosity = "medium"
                
                logger.info(f"OpenAI Responses API: model={model}, reasoning_effort={reasoning_effort}, verbosity={verbosity}")
                
                # Sprawd≈∫ czy SDK ma responses API
                if not hasattr(client, 'responses'):
                    logger.warning(f"SDK brak responses API - fallback do chat completions dla {model}")
                    raise AttributeError("No responses API in SDK")
                # U≈ºyj minimalnie wymaganego, zgodnego schematu Responses API
                # Wprowadzamy system prompt jako 'instructions', a tre≈õƒá jako input_text
                response = client.responses.create(
                    model=model,
                    instructions=current_system_prompt,
                    input=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "input_text", "text": f"{instruction_prompt}\n\n---\n{text_to_correct}\n---"}
                            ],
                        }
                    ],
                    max_output_tokens=2000
                )
                # Responses API: zbuduj tekst
                logger.info(f"Responses API response type: {type(response)}")
                logger.info(f"Response hasattr output: {hasattr(response, 'output')}")
                logger.info(f"Response hasattr content: {hasattr(response, 'content')}")
                
                # Najpierw spr√≥buj prostego accessor'a je≈õli dostƒôpny w SDK
                if hasattr(response, 'output_text') and getattr(response, 'output_text'):
                    corrected_text = (getattr(response, 'output_text') or '').strip()
                
                text_chunks = [] if not corrected_text else [corrected_text]
                if hasattr(response, 'output') and response.output:
                    logger.info(f"Processing response.output with {len(response.output)} items")
                    for item in response.output:
                        item_type = getattr(item, 'type', None)
                        logger.debug(f"Output item type: {item_type}")
                        if item_type == 'message' and getattr(item, 'content', None):
                            for part in item.content:
                                part_type = getattr(part, 'type', None)
                                logger.debug(f"Content part type: {part_type}")
                                if part_type == 'output_text':
                                    text = getattr(part, 'text', '') or ''
                                    logger.debug(f"Found output_text: {text[:100]}...")
                                    text_chunks.append(text)
                elif hasattr(response, 'content') and response.content:
                    logger.info(f"Processing response.content with {len(response.content)} parts")
                    # Starsze obiekty mogƒÖ mieƒá content
                    for part in response.content:
                        part_type = getattr(part, 'type', None)
                        logger.debug(f"Content part type: {part_type}")
                        if part_type == 'output_text':
                            text = getattr(part, 'text', '') or ''
                            logger.debug(f"Found output_text: {text[:100]}...")
                            text_chunks.append(text)
                else:
                    logger.warning("No output or content found in Responses API response")
                    logger.info(f"Response attributes: {dir(response)}")
                
                corrected_text = ("".join(text_chunks)).strip()
                logger.info(f"Extracted text length: {len(corrected_text)} chars")
            else:
                logger.info(f"üîç DEBUG: U≈ºywam Chat Completions API dla modelu: {model}")
                response = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=2000
                )
                logger.info(f"üîç DEBUG: Chat Completions response received")
                # Chat Completions API
                if response.choices and response.choices[0].message:
                    corrected_text = (response.choices[0].message.content or '').strip()
                    logger.info(f"üîç DEBUG: Extracted from choices[0].message.content: {len(corrected_text)} chars")
                else:
                    corrected_text = ""
                    logger.warning(f"üîç DEBUG: No choices or message in response")
        except (AttributeError, TypeError, Exception) as e:
            # Fallback: SDK nie ma responses API, model nie wspiera parametr√≥w reasoning, lub inne b≈Çƒôdy API
            logger.warning(f"Responses API fallback dla {model}: {type(e).__name__}: {e}")
            
            # Pr√≥buj standardowe Chat Completions API
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=2000
                )
                corrected_text = (response.choices[0].message.content or '').strip() if (response.choices and response.choices[0].message) else ""
                logger.info(f"Chat Completions API fallback successful, text length: {len(corrected_text)} chars")
            except Exception as fallback_error:
                logger.error(f"Both Responses and Chat Completions API failed for {model}: {fallback_error}")
                # Sprawd≈∫ typowe liter√≥wki w nazwie modelu
                if "gtp-5" in model.lower():
                    suggested_model = model.replace("gtp-5", "gpt-5")
                    return f"B≈ÇƒÖd: Model {model} niedostƒôpny. Czy chodzi≈Ço o '{suggested_model}'? Popraw nazwƒô modelu w ustawieniach."
                return f"B≈ÇƒÖd: Model {model} niedostƒôpny. Sprawd≈∫ nazwƒô modelu lub spr√≥buj gpt-4o-mini."

        # Przetworzenie odpowiedzi
        logger.info(f"üîç DEBUG: corrected_text d≈Çugo≈õƒá: {len(corrected_text) if corrected_text else 'None'}")
        logger.info(f"üîç DEBUG: corrected_text content (50 chars): {corrected_text[:50] if corrected_text else 'EMPTY'}")
        
        if corrected_text:
            logger.info("‚úÖ Otrzymano poprawnƒÖ odpowied≈∫ od OpenAI API.")
            logger.info(f"üîç DEBUG: Original response (100 chars): '{corrected_text[:100]}...'")
            
            # Czyszczenie odpowiedzi - bardziej ostro≈ºne
            original_text = corrected_text
            corrected_text = corrected_text.strip()
            logger.info(f"üîç DEBUG: Po strip: {len(corrected_text)} chars")
            
            # Usu≈Ñ wszystkie wystƒÖpienia --- z poczƒÖtku i ko≈Ñca (ale zachowaj tre≈õƒá)
            while corrected_text.startswith("---"):
                corrected_text = corrected_text[3:].strip()
                logger.info(f"üîç DEBUG: Po usuwaniu --- z poczƒÖtku: {len(corrected_text)} chars")
            while corrected_text.endswith("---"):
                corrected_text = corrected_text[:-3].strip()
                logger.info(f"üîç DEBUG: Po usuwaniu --- z ko≈Ñca: {len(corrected_text)} chars")
            
            # Dodatkowe czyszczenie - usu≈Ñ linie zawierajƒÖce same ---
            lines_before = corrected_text.splitlines()
            lines = [line for line in lines_before if line.strip() != "---"]
            logger.info(f"üîç DEBUG: Linie przed: {len(lines_before)}, po usuniƒôciu ---: {len(lines)}")
            corrected_text = "\n".join(lines).strip()
            
            # Usu≈Ñ puste linie na poczƒÖtku i ko≈Ñcu (ale zostaw niepuste)
            lines = [line for line in corrected_text.splitlines() if line.strip()]
            logger.info(f"üîç DEBUG: Po usuniƒôciu pustych linii: {len(lines)} linii")
            
            # Usu≈Ñ pierwszƒÖ liniƒô je≈õli to nazwa stylu
            style_names = ["normal", "professional", "translate_en", "translate_pl", "change_meaning", "summary"]
            if lines and any(style in lines[0].lower() for style in style_names):
                logger.info(f"üîç DEBUG: Usuwam pierwszƒÖ liniƒô (style): '{lines[0]}'")
                lines = lines[1:]
            
            final_result = "\n".join(lines).strip()
            logger.info(f"üîç DEBUG: Final result: {len(final_result)} chars: '{final_result[:100]}...'")
            
            # Je≈õli po czyszczeniu nic nie zosta≈Ço, zwr√≥ƒá original
            if not final_result and original_text:
                logger.warning(f"‚ùå Czyszczenie usunƒô≈Ço ca≈ÇƒÖ tre≈õƒá! Zwracam oryginalnƒÖ odpowied≈∫")
                return original_text.strip()
            
            return final_result
        else:
            logger.warning("Otrzymano odpowied≈∫ od OpenAI, ale tre≈õƒá jest pusta.")
            return "B≈ÇƒÖd: Nie otrzymano poprawnej odpowiedzi od OpenAI API (brak tre≈õci w wiadomo≈õci)."

    except (httpx.TimeoutException, httpx.ReadTimeout, httpx.ConnectTimeout) as e:
        logger.error(f"Timeout OpenAI API: {e}", exc_info=True)
        return f"B≈ÇƒÖd: OpenAI API nie odpowiada (timeout {DEFAULT_TIMEOUT}s). Spr√≥buj ponownie."
    except (HTTPError, TimeoutException, openai.APIConnectionError) as e:
        if handle_api_error(e):
            return "B≈ÇƒÖd po≈ÇƒÖczenia z API. Sprawd≈∫ komunikat b≈Çƒôdu."
        logger.error(f"B≈ÇƒÖd po≈ÇƒÖczenia z OpenAI API: {e}", exc_info=True) # Logowanie b≈Çƒôdu
        return f"B≈ÇƒÖd po≈ÇƒÖczenia z OpenAI API: {e}"
    except openai.RateLimitError as e:
        logger.warning(f"Przekroczono limit zapyta≈Ñ do OpenAI API: {e}") # Logowanie ostrze≈ºenia
        return f"B≈ÇƒÖd OpenAI (limit zapyta≈Ñ): {e}"
    except openai.AuthenticationError as e:
        logger.error(f"B≈ÇƒÖd autentykacji OpenAI API (prawdopodobnie z≈Çy klucz): {e}", exc_info=True) # Logowanie b≈Çƒôdu
        return f"B≈ÇƒÖd OpenAI (autentykacja - z≈Çy klucz?): {e}"
    except openai.APIStatusError as e:
        logger.error(f"Og√≥lny b≈ÇƒÖd statusu OpenAI API: {e} (Status: {e.status_code}, Response: {e.response})", exc_info=True) # Logowanie b≈Çƒôdu z dodatkowymi informacjami
        return f"B≈ÇƒÖd OpenAI (status API {e.status_code}): {e.response}"
    except Exception as e:
        logger.error(f"Nieoczekiwany b≈ÇƒÖd podczas komunikacji z OpenAI: {e}", exc_info=True) # Logowanie b≈Çƒôdu
        return f"B≈ÇƒÖd OpenAI (nieoczekiwany): {e}"


if __name__ == '__main__':
    # Prosty test dzia≈Çania (wymaga ustawienia klucza API i modelu poni≈ºej lub w zmiennych ≈õrodowiskowych)
    # Pamiƒôtaj, aby zastƒÖpiƒá 'YOUR_OPENAI_API_KEY' i 'YOUR_MODEL' (np. "gpt-3.5-turbo")
    # lub za≈Çadowaƒá je z pliku konfiguracyjnego.

    # --- Modyfikacja sys.path dla testowania bezpo≈õredniego ---
    # Zak≈Çadamy, ≈ºe ten plik (openai_client.py) jest w PoprawiaczTekstuPy/api_clients/
    # Musimy dodaƒá PoprawiaczTekstuPy do sys.path, aby importy z api_clients zadzia≈Ça≈Çy
    current_script_path = os.path.abspath(__file__)
    # api_clients_dir to .../PoprawiaczTekstuPy/api_clients
    api_clients_dir = os.path.dirname(current_script_path)
    # project_root_dir to .../PoprawiaczTekstuPy
    project_root_dir = os.path.dirname(api_clients_dir)
    
    if project_root_dir not in sys.path:
        sys.path.insert(0, project_root_dir)
    
    # Teraz mo≈ºemy spr√≥bowaƒá importu, kt√≥ry wcze≈õniej zawodzi≈Ç, je≈õli by≈Ç potrzebny
    # from api_clients.base_client import APIConnectionError, APIResponseError # Przyk≈Çad
    # W tym konkretnym pliku openai_client.py nie u≈ºywamy niczego z base_client,
    # wiƒôc linia 'from .base_client import...' na g√≥rze mo≈ºe zostaƒá usuniƒôta lub zakomentowana
    # je≈õli nie planujemy jej u≈ºywaƒá.
    # Dla czysto≈õci, je≈õli nie jest u≈ºywana, lepiej jƒÖ usunƒÖƒá.
    # Na potrzeby tego testu, zak≈Çadamy, ≈ºe nie jest potrzebna w tym pliku.

    # --- PRZYK≈ÅAD U≈ªYCIA --- 
    # Ustaw poni≈ºsze zmienne przed uruchomieniem tego bloku testowego
    test_api_key = "YOUR_DEEPSEEK_API_KEY"  # Wstaw sw√≥j klucz OpenAI
    test_model = "o4-mini"      # Wstaw model, np. "gpt-3.5-turbo"
    
    if test_api_key == "YOUR_OPENAI_API_KEY" or not test_api_key:
        print("Aby przetestowaƒá, ustaw `test_api_key` oraz `test_model` w sekcji if __name__ == '__main__'.")
    else:
        sample_text = "To jest tekst z b≈Çendem ortograficznym i gramatycznym. Popraw go proszƒô."
        sample_instruction = "Popraw nastƒôpujƒÖcy tekst, zachowujƒÖc jego formatowanie."
        sample_system_prompt = (
            'You are a virtual editor specializing in proofreading Polish texts. '
            'Your goal is to transform the provided text into correct, clear, and professional-sounding Polish, '
            'eliminating all language errors. The input text will be in Polish. Instructions: '
            '1. **Error-Free**: Detect and correct ALL spelling, grammatical, punctuation, and stylistic errors. Focus on precision and compliance with Polish language standards. '
            '2. **Clarity and Conciseness**: Simplify complex sentences while preserving their technical meaning. Aim for clear and precise communication. Eliminate redundant words and repetitions. '
            '3. **IT Terminology**: Preserve original technical terms, proper names, acronyms, and code snippets, unless they contain obvious spelling mistakes. Do not change their meaning. '
            '4. **Professional Tone**: Give the text a professional yet natural tone. Avoid colloquialisms, but also excessive formality. '
            '5. **Formatting**: Strictly preserve the original text formatting: paragraphs, bulleted/numbered lists, indentations, bolding (if Markdown was used), and line breaks. '
            '6. **Text Only**: As the result, return ONLY the final, corrected Polish text, without any additional comments, headers, or explanations.'
        )
        
        print(f"Wysy≈Çanie zapytania do OpenAI z modelem: {test_model}...")
        result = correct_text_openai(test_api_key, test_model, sample_text, sample_instruction, sample_system_prompt)
        print("--- Wynik z OpenAI ---")
        print(result)
        print("----------------------") 