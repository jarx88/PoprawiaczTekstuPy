# from .base_client import APIConnectionError, APIResponseError, DEFAULT_TIMEOUT # Zakomentowano - nieuÅ¼ywane w tym pliku
import time # Dla symulacji opÃ³Åºnienia
import openai
import os
import sys # Dodano import sys
from datetime import datetime
import ssl
import httpx
from httpx import HTTPError, TimeoutException
# PyQt6 removed - using CustomTkinter GUI now
from gui.prompts import get_system_prompt
from .base_client import DEFAULT_TIMEOUT, QUICK_TIMEOUT, CONNECTION_TIMEOUT, DEFAULT_RETRIES, APITimeoutError

# Importujemy logger z odpowiedniego miejsca w strukturze projektu
# ZakÅ‚adamy, Å¼e api_clients jest na tym samym poziomie co utils
# wiÄ™c potrzebujemy .utils.logger
try:
    from utils.logger import logger
    from utils.config_manager import get_config_value
except ImportError:
    # Fallback logger w przypadku problemÃ³w z importem (np. bezpoÅ›rednie uruchamianie)
    import logging
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO) # DomyÅ›lny poziom dla fallbacka
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# Klucz API OpenAI jest teraz przekazywany jako argument do funkcji,
# ale moÅ¼na teÅ¼ ustawiÄ‡ go globalnie przez zmiennÄ… Å›rodowiskowÄ… OPENAI_API_KEY
# JeÅ›li chcesz uÅ¼ywaÄ‡ zmiennej Å›rodowiskowej, odkomentuj:
# openai.api_key = os.getenv("OPENAI_API_KEY")

# Tymczasowo usuwamy import relatywny, jeÅ›li bÄ™dziemy go potrzebowaÄ‡ pÃ³Åºniej, przywrÃ³cimy
# from .base_client import APIConnectionError, APIResponseError, DEFAULT_TIMEOUT

def show_connection_error():
    """Log connection error - GUI now handled by main application"""
    logger.error("Connection error - cannot connect to API server")
    logger.error("Possible causes: 1) No internet 2) Firewall blocking 3) API server down")

def handle_api_error(e):
    if isinstance(e, (httpx.ConnectError, httpx.ConnectTimeout, openai.APIConnectionError)):
        logger.error(f"BÅ‚Ä…d poÅ‚Ä…czenia: {str(e)}")
        show_connection_error()
        return True
    return False

def correct_text_openai(api_key, model, text_to_correct, instruction_prompt, system_prompt, on_chunk=None):
    """Poprawia tekst uÅ¼ywajÄ…c OpenAI API."""
    
        
    if not api_key:
        logger.warning("PrÃ³ba uÅ¼ycia OpenAI API bez klucza.") # Logowanie ostrzeÅ¼enia
        return "BÅ‚Ä…d: Klucz API OpenAI nie zostaÅ‚ podany."
    if not model:
        logger.warning("PrÃ³ba uÅ¼ycia OpenAI API bez podania modelu.") # Logowanie ostrzeÅ¼enia
        return "BÅ‚Ä…d: Model OpenAI nie zostaÅ‚ okreÅ›lony."
    if not text_to_correct:
        logger.warning("PrÃ³ba uÅ¼ycia OpenAI API bez tekstu do poprawy.") # Logowanie ostrzeÅ¼enia
        return "BÅ‚Ä…d: Brak tekstu do poprawy."

    logger.info(f"WysyÅ‚anie zapytania do OpenAI API (model: {model}). Tekst: {text_to_correct[:50]}...") # Logowanie rozpoczÄ™cia zapytania

    try:
        # Inicjalizacja klienta OpenAI z ulepszonÄ… konfiguracjÄ…
        client = openai.OpenAI(
            api_key=api_key,
            timeout=httpx.Timeout(
                connect=CONNECTION_TIMEOUT,  # 5s na poÅ‚Ä…czenie
                read=DEFAULT_TIMEOUT,        # 15s na odczyt
                write=CONNECTION_TIMEOUT,    # 5s na zapis
                pool=CONNECTION_TIMEOUT      # 5s na pool
            ),
            max_retries=DEFAULT_RETRIES,  # 2 prÃ³by zamiast 3
            http_client=httpx.Client(
                timeout=httpx.Timeout(
                    connect=CONNECTION_TIMEOUT,
                    read=DEFAULT_TIMEOUT,
                    write=CONNECTION_TIMEOUT,
                    pool=CONNECTION_TIMEOUT
                )
            )
        )

        # Pobierz odpowiedni system prompt w zaleÅ¼noÅ›ci od stylu
        current_system_prompt = get_system_prompt("prompt" if "prompt" in instruction_prompt.lower() else "normal")
        
        # Przygotowanie wiadomoÅ›ci dla Chat Completions API
        messages = [
            {"role": "system", "content": current_system_prompt},
            {"role": "user", "content": f"{instruction_prompt}\n\n---\n{text_to_correct}\n---"}
        ]

        # WysÅ‚anie zapytania do API z timeout
        response = None
        
        logger.info(f"ğŸ” DEBUG: Rozpoczynam korekcjÄ™ dla modelu: {model}")

        # GPT-5 i o1 modele WYMAGAJÄ„ Responses API (nie dziaÅ‚ajÄ… z Chat Completions)
        # gpt-4o-mini uÅ¼ywa Chat Completions API
        use_responses_api = any(model.lower().startswith(prefix) for prefix in ["gpt-5", "o1"])
        
        logger.info(f"ğŸ” DEBUG: Model: {model}, use_responses_api: {use_responses_api}")
        
        try:
            if use_responses_api:
                # Responses API dla nowszych modeli z reasoning controls
                # Pobierz ustawienia z config.ini lub uÅ¼yj domyÅ›lnych
                try:
                    import configparser
                    from utils.config_manager import get_config_path
                    config = configparser.ConfigParser()
                    config.read(get_config_path())
                    reasoning_effort = get_config_value(config, "AI_SETTINGS", "ReasoningEffort", "high")
                    verbosity = get_config_value(config, "AI_SETTINGS", "Verbosity", "medium")
                except:
                    # Fallback values jeÅ›li problem z konfiguracjÄ…
                    reasoning_effort = "high"
                    verbosity = "medium"
                
                logger.info(f"OpenAI Responses API: model={model}, reasoning_effort={reasoning_effort}, verbosity={verbosity}")
                
                # SprawdÅº czy SDK ma responses API
                if not hasattr(client, 'responses'):
                    logger.warning(f"SDK brak responses API - fallback do chat completions dla {model}")
                    raise AttributeError("No responses API in SDK")
                # PRAWIDÅOWA skÅ‚adnia Responses API z dokumentacji OpenAI 2025
                # Test rÃ³Å¼nych formatÃ³w nazwy modelu
                model_variants = [model]
                if model == "gpt-5-mini":
                    model_variants = ["gpt-5-mini", "gpt-5-mini-2025-08-07", "gpt-5-mini-preview", "o1-mini", "gpt-4o-mini"]
                elif model == "gpt-5":
                    model_variants = ["gpt-5", "gpt-5-2025-08-07", "gpt-5-preview", "o1-preview", "gpt-4o"]
                elif model == "o1-mini":
                    model_variants = ["o1-mini", "gpt-4o-mini"]
                
                response = None
                last_error = None
                
                for variant in model_variants:
                    try:
                        logger.info(f"PrÃ³bujÄ™ model variant: {variant}")
                        response = client.responses.create(
                            model=variant,
                            input=f"{current_system_prompt}\n\n{instruction_prompt}\n\n---\n{text_to_correct}\n---",
                            reasoning={
                                "effort": reasoning_effort,  # "minimal", "low", "medium", "high"
                                "summary": "auto"
                            },
                            text={
                                "verbosity": verbosity  # "low", "medium", "high"
                            },
                            max_output_tokens=2000
                        )
                        logger.info(f"âœ… Sukces z modelem: {variant}")
                        break
                    except Exception as variant_error:
                        logger.warning(f"Model {variant} failed: {variant_error}")
                        last_error = variant_error
                        continue
                
                if response is None:
                    raise last_error or Exception("All model variants failed")
                # Responses API: preferuj output_text jeÅ›li dostÄ™pny, bez sklejania duplikatÃ³w
                logger.info(f"Responses API response type: {type(response)}")
                logger.info(f"Response hasattr output: {hasattr(response, 'output')}")
                logger.info(f"Response hasattr content: {hasattr(response, 'content')}")

                # PRAWIDÅOWE parsowanie Responses API zgodnie z dokumentacjÄ…
                corrected_text = ""
                if hasattr(response, 'output_text') and response.output_text:
                    # BezpoÅ›redni dostÄ™p do output_text 
                    corrected_text = response.output_text.strip()
                    logger.info(f"Got output_text directly: {len(corrected_text)} chars")
                elif hasattr(response, 'response') and response.response:
                    # Alternatywna struktura
                    corrected_text = response.response.strip()
                    logger.info(f"Got response field: {len(corrected_text)} chars")
                else:
                    logger.warning("No output_text or response field found in Responses API")
                    logger.info(f"Response attributes: {[attr for attr in dir(response) if not attr.startswith('_')]}")
                    corrected_text = str(response) if response else ""
                logger.info(f"Extracted text length: {len(corrected_text)} chars")
            else:
                logger.info(f"ğŸ” DEBUG: UÅ¼ywam Chat Completions API dla modelu: {model}")
                if callable(on_chunk):
                    # Streaming delta
                    stream = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        stream=True,
                        max_tokens=2000
                    )
                    collected = []
                    try:
                        for chunk in stream:
                            try:
                                delta = chunk.choices[0].delta.content or ''
                            except Exception:
                                delta = ''
                            if delta:
                                collected.append(delta)
                                try:
                                    on_chunk(delta)
                                except Exception:
                                    pass
                    except Exception as e:
                        logger.warning(f"OpenAI stream interrupted: {e}")
                    corrected_text = ("".join(collected)).strip()
                else:
                    response = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        max_tokens=2000
                    )
                    logger.info(f"ğŸ” DEBUG: Chat Completions response received")
                    # Chat Completions API
                    if response.choices and response.choices[0].message:
                        corrected_text = (response.choices[0].message.content or '').strip()
                        logger.info(f"ğŸ” DEBUG: Extracted from choices[0].message.content: {len(corrected_text)} chars")
                    else:
                        corrected_text = ""
                        logger.warning(f"ğŸ” DEBUG: No choices or message in response")
        except (AttributeError, TypeError, Exception) as e:
            # GPT-5 modele dziaÅ‚ajÄ… TYLKO z Responses API - nie prÃ³buj fallback do Chat Completions
            if use_responses_api and any(model.lower().startswith(prefix) for prefix in ["gpt-5", "o1"]):
                logger.error(f"GPT-5 model {model} failed with Responses API: {type(e).__name__}: {e}")
                # MoÅ¼liwe przyczyny: bÅ‚Ä™dna nazwa modelu, brak dostÄ™pu, stary SDK
                if "404" in str(e) or "not found" in str(e).lower():
                    return f"BÅ‚Ä…d: Model {model} nie zostaÅ‚ znaleziony. MoÅ¼liwe nazwy: gpt-5-mini, gpt-5-nano, gpt-5. SprawdÅº dostÄ™p do GPT-5 models w OpenAI account."
                elif "authentication" in str(e).lower():
                    return f"BÅ‚Ä…d: Brak autoryzacji dla {model}. SprawdÅº klucz API i dostÄ™p do GPT-5 models."
                else:
                    return f"BÅ‚Ä…d GPT-5 Responses API: {e}. SprawdÅº SDK version: pip install openai --upgrade"
            
            # Fallback: SDK nie ma responses API, model nie wspiera parametrÃ³w reasoning, lub inne bÅ‚Ä™dy API
            logger.warning(f"Responses API fallback dla {model}: {type(e).__name__}: {e}")
            
            # PrÃ³buj standardowe Chat Completions API (tylko dla nie-GPT-5 modeli)
            try:
                if callable(on_chunk):
                    stream = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        stream=True,
                        max_tokens=2000
                    )
                    collected = []
                    try:
                        for chunk in stream:
                            try:
                                delta = chunk.choices[0].delta.content or ''
                            except Exception:
                                delta = ''
                            if delta:
                                collected.append(delta)
                                try:
                                    on_chunk(delta)
                                except Exception:
                                    pass
                    except Exception as e:
                        logger.warning(f"OpenAI stream (fallback) interrupted: {e}")
                    corrected_text = ("".join(collected)).strip()
                else:
                    response = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        max_tokens=2000
                    )
                    corrected_text = (response.choices[0].message.content or '').strip() if (response.choices and response.choices[0].message) else ""
                logger.info(f"Chat Completions API fallback successful, text length: {len(corrected_text)} chars")
            except Exception as fallback_error:
                logger.error(f"Both Responses and Chat Completions API failed for {model}: {fallback_error}")
                # SprawdÅº typowe literÃ³wki w nazwie modelu
                if "gtp-5" in model.lower():
                    suggested_model = model.replace("gtp-5", "gpt-5")
                    return f"BÅ‚Ä…d: Model {model} niedostÄ™pny. Czy chodziÅ‚o o '{suggested_model}'? Popraw nazwÄ™ modelu w ustawieniach."
                return f"BÅ‚Ä…d: Model {model} niedostÄ™pny. SprawdÅº nazwÄ™ modelu lub sprÃ³buj gpt-4o-mini."

        # Przetworzenie odpowiedzi
        logger.info(f"ğŸ” DEBUG: corrected_text dÅ‚ugoÅ›Ä‡: {len(corrected_text) if corrected_text else 'None'}")
        logger.info(f"ğŸ” DEBUG: corrected_text content (50 chars): {corrected_text[:50] if corrected_text else 'EMPTY'}")
        
        if corrected_text:
            logger.info("âœ… Otrzymano poprawnÄ… odpowiedÅº od OpenAI API.")
            logger.info(f"ğŸ” DEBUG: Original response (100 chars): '{corrected_text[:100]}...'")
            
            # Czyszczenie odpowiedzi - bardziej ostroÅ¼ne
            original_text = corrected_text
            corrected_text = corrected_text.strip()
            logger.info(f"ğŸ” DEBUG: Po strip: {len(corrected_text)} chars")
            
            # UsuÅ„ wszystkie wystÄ…pienia --- z poczÄ…tku i koÅ„ca (ale zachowaj treÅ›Ä‡)
            while corrected_text.startswith("---"):
                corrected_text = corrected_text[3:].strip()
                logger.info(f"ğŸ” DEBUG: Po usuwaniu --- z poczÄ…tku: {len(corrected_text)} chars")
            while corrected_text.endswith("---"):
                corrected_text = corrected_text[:-3].strip()
                logger.info(f"ğŸ” DEBUG: Po usuwaniu --- z koÅ„ca: {len(corrected_text)} chars")
            
            # Dodatkowe czyszczenie - usuÅ„ linie zawierajÄ…ce same ---
            lines_before = corrected_text.splitlines()
            lines = [line for line in lines_before if line.strip() != "---"]
            logger.info(f"ğŸ” DEBUG: Linie przed: {len(lines_before)}, po usuniÄ™ciu ---: {len(lines)}")
            corrected_text = "\n".join(lines).strip()
            
            # UsuÅ„ puste linie na poczÄ…tku i koÅ„cu (ale zostaw niepuste)
            lines = [line for line in corrected_text.splitlines() if line.strip()]
            logger.info(f"ğŸ” DEBUG: Po usuniÄ™ciu pustych linii: {len(lines)} linii")
            
            # UsuÅ„ pierwszÄ… liniÄ™ jeÅ›li to nazwa stylu
            style_names = ["normal", "professional", "translate_en", "translate_pl", "change_meaning", "summary"]
            if lines and any(style in lines[0].lower() for style in style_names):
                logger.info(f"ğŸ” DEBUG: Usuwam pierwszÄ… liniÄ™ (style): '{lines[0]}'")
                lines = lines[1:]
            
            final_result = "\n".join(lines).strip()
            logger.info(f"ğŸ” DEBUG: Final result: {len(final_result)} chars: '{final_result[:100]}...'")
            
            # DEDUPLIKACJA - usuÅ„ powtarzajÄ…ce siÄ™ fragmenty (fix dla bugÃ³w OpenAI API)
            if final_result:
                # Podziel na zdania
                sentences = [s.strip() for s in final_result.split('.') if s.strip()]
                # UsuÅ„ duplikaty zachowujÄ…c kolejnoÅ›Ä‡
                unique_sentences = []
                seen = set()
                for sentence in sentences:
                    if sentence not in seen and len(sentence) > 3:  # Ignoruj bardzo krÃ³tkie
                        seen.add(sentence)
                        unique_sentences.append(sentence)
                
                if unique_sentences:
                    final_result = '. '.join(unique_sentences)
                    if not final_result.endswith('.'):
                        final_result += '.'
                    logger.info(f"ğŸ” DEBUG: Po deduplikacji: {len(final_result)} chars")
            
            # JeÅ›li po czyszczeniu nic nie zostaÅ‚o, zwrÃ³Ä‡ original
            if not final_result and original_text:
                logger.warning(f"âŒ Czyszczenie usunÄ™Å‚o caÅ‚Ä… treÅ›Ä‡! Zwracam oryginalnÄ… odpowiedÅº")
                return original_text.strip()
            
            return final_result
        else:
            logger.warning("Otrzymano odpowiedÅº od OpenAI, ale treÅ›Ä‡ jest pusta.")
            return "BÅ‚Ä…d: Nie otrzymano poprawnej odpowiedzi od OpenAI API (brak treÅ›ci w wiadomoÅ›ci)."

    except (httpx.TimeoutException, httpx.ReadTimeout, httpx.ConnectTimeout) as e:
        logger.error(f"Timeout OpenAI API: {e}", exc_info=True)
        return f"BÅ‚Ä…d: OpenAI API nie odpowiada (timeout {DEFAULT_TIMEOUT}s). SprÃ³buj ponownie."
    except (HTTPError, TimeoutException, openai.APIConnectionError) as e:
        if handle_api_error(e):
            return "BÅ‚Ä…d poÅ‚Ä…czenia z API. SprawdÅº komunikat bÅ‚Ä™du."
        logger.error(f"BÅ‚Ä…d poÅ‚Ä…czenia z OpenAI API: {e}", exc_info=True) # Logowanie bÅ‚Ä™du
        return f"BÅ‚Ä…d poÅ‚Ä…czenia z OpenAI API: {e}"
    except openai.RateLimitError as e:
        logger.warning(f"Przekroczono limit zapytaÅ„ do OpenAI API: {e}") # Logowanie ostrzeÅ¼enia
        return f"BÅ‚Ä…d OpenAI (limit zapytaÅ„): {e}"
    except openai.AuthenticationError as e:
        logger.error(f"BÅ‚Ä…d autentykacji OpenAI API (prawdopodobnie zÅ‚y klucz): {e}", exc_info=True) # Logowanie bÅ‚Ä™du
        return f"BÅ‚Ä…d OpenAI (autentykacja - zÅ‚y klucz?): {e}"
    except openai.APIStatusError as e:
        logger.error(f"OgÃ³lny bÅ‚Ä…d statusu OpenAI API: {e} (Status: {e.status_code}, Response: {e.response})", exc_info=True) # Logowanie bÅ‚Ä™du z dodatkowymi informacjami
        return f"BÅ‚Ä…d OpenAI (status API {e.status_code}): {e.response}"
    except Exception as e:
        logger.error(f"Nieoczekiwany bÅ‚Ä…d podczas komunikacji z OpenAI: {e}", exc_info=True) # Logowanie bÅ‚Ä™du
        return f"BÅ‚Ä…d OpenAI (nieoczekiwany): {e}"


if __name__ == '__main__':
    # Prosty test dziaÅ‚ania (wymaga ustawienia klucza API i modelu poniÅ¼ej lub w zmiennych Å›rodowiskowych)
    # PamiÄ™taj, aby zastÄ…piÄ‡ 'YOUR_OPENAI_API_KEY' i 'YOUR_MODEL' (np. "gpt-3.5-turbo")
    # lub zaÅ‚adowaÄ‡ je z pliku konfiguracyjnego.

    # --- Modyfikacja sys.path dla testowania bezpoÅ›redniego ---
    # ZakÅ‚adamy, Å¼e ten plik (openai_client.py) jest w PoprawiaczTekstuPy/api_clients/
    # Musimy dodaÄ‡ PoprawiaczTekstuPy do sys.path, aby importy z api_clients zadziaÅ‚aÅ‚y
    current_script_path = os.path.abspath(__file__)
    # api_clients_dir to .../PoprawiaczTekstuPy/api_clients
    api_clients_dir = os.path.dirname(current_script_path)
    # project_root_dir to .../PoprawiaczTekstuPy
    project_root_dir = os.path.dirname(api_clients_dir)
    
    if project_root_dir not in sys.path:
        sys.path.insert(0, project_root_dir)
    
    # Teraz moÅ¼emy sprÃ³bowaÄ‡ importu, ktÃ³ry wczeÅ›niej zawodziÅ‚, jeÅ›li byÅ‚ potrzebny
    # from api_clients.base_client import APIConnectionError, APIResponseError # PrzykÅ‚ad
    # W tym konkretnym pliku openai_client.py nie uÅ¼ywamy niczego z base_client,
    # wiÄ™c linia 'from .base_client import...' na gÃ³rze moÅ¼e zostaÄ‡ usuniÄ™ta lub zakomentowana
    # jeÅ›li nie planujemy jej uÅ¼ywaÄ‡.
    # Dla czystoÅ›ci, jeÅ›li nie jest uÅ¼ywana, lepiej jÄ… usunÄ…Ä‡.
    # Na potrzeby tego testu, zakÅ‚adamy, Å¼e nie jest potrzebna w tym pliku.

    # --- PRZYKÅAD UÅ»YCIA --- 
    # Ustaw poniÅ¼sze zmienne przed uruchomieniem tego bloku testowego
    test_api_key = "YOUR_DEEPSEEK_API_KEY"  # Wstaw swÃ³j klucz OpenAI
    test_model = "o4-mini"      # Wstaw model, np. "gpt-3.5-turbo"
    
    if test_api_key == "YOUR_OPENAI_API_KEY" or not test_api_key:
        print("Aby przetestowaÄ‡, ustaw `test_api_key` oraz `test_model` w sekcji if __name__ == '__main__'.")
    else:
        sample_text = "To jest tekst z bÅ‚endem ortograficznym i gramatycznym. Popraw go proszÄ™."
        sample_instruction = "Popraw nastÄ™pujÄ…cy tekst, zachowujÄ…c jego formatowanie."
        sample_system_prompt = (
            'You are a virtual editor specializing in proofreading Polish texts. '
            'Your goal is to transform the provided text into correct, clear, and professional-sounding Polish, '
            'eliminating all language errors. The input text will be in Polish. Instructions: '
            '1. **Error-Free**: Detect and correct ALL spelling, grammatical, punctuation, and stylistic errors. Focus on precision and compliance with Polish language standards. '
            '2. **Clarity and Conciseness**: Simplify complex sentences while preserving their technical meaning. Aim for clear and precise communication. Eliminate redundant words and repetitions. '
            '3. **IT Terminology**: Preserve original technical terms, proper names, acronyms, and code snippets, unless they contain obvious spelling mistakes. Do not change their meaning. '
            '4. **Professional Tone**: Give the text a professional yet natural tone. Avoid colloquialisms, but also excessive formality. '
            '5. **Formatting**: Strictly preserve the original text formatting: paragraphs, bulleted/numbered lists, indentations, bolding (if Markdown was used), and line breaks. '
            '6. **Text Only**: As the result, return ONLY the final, corrected Polish text, without any additional comments, headers, or explanations.'
        )
        
        print(f"WysyÅ‚anie zapytania do OpenAI z modelem: {test_model}...")
        result = correct_text_openai(test_api_key, test_model, sample_text, sample_instruction, sample_system_prompt)
        print("--- Wynik z OpenAI ---")
        print(result)
        print("----------------------") 